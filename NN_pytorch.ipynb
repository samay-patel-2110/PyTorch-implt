{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = 28*28  # we receive the size of images in MNIST as 28x28\n",
    "# as we are having neural network the input shape\n",
    "# will be 28*28 and we will flatten each image to\n",
    "# match the input size of model\n",
    "classes = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NN, self).__init__()\n",
    "        self.nn1 = nn.Linear(input_size, 50)\n",
    "        self.nn2 = nn.Linear(50, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.nn1(x))\n",
    "        x = self.nn2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(input_size=input_shape, num_classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root=\"dataset/\", train=True,\n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "test_dataset = datasets.MNIST(root=\"dataset/\", train=False,\n",
    "                              transform=transforms.ToTensor(),\n",
    "                              download=True)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epochs in range(num_epochs):\n",
    "    for batch_idx, (train, targets) in enumerate(train_loader):\n",
    "        data = train\n",
    "        targets = targets  # now we have loaded the data\n",
    "\n",
    "        # Flatten it to input it into nn\n",
    "        data = data.reshape(data.shape[0], -1)\n",
    "        print(data.shape)\n",
    "        # now fit the model\n",
    "        scores = model(data)\n",
    "        loss = metrics(scores, targets)\n",
    "        print(scores.shape)\n",
    "        # CAlculate gradient of the loss wrt the parameters\n",
    "        # set optimizer's gradients to zero for every batch initially\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print(\"testing on training data\")\n",
    "    else:\n",
    "        print(\"Testing on Testing data\")\n",
    "\n",
    "    num_correct = 0\n",
    "    num_sample = 0\n",
    "    model.eval()  # We're telling model to shift to eval mode\n",
    "\n",
    "    with torch.no_grad():   # we dont want the model to calculate the graidents\n",
    "        # just the outputs are required as model is already trained\n",
    "        for x, y in loader:\n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "            scores = model(x)\n",
    "            # scores.max = ([max_values], [indices of max value])\n",
    "            # Shape = batchsize\n",
    "            # here indices represent class with max prob\n",
    "            _, predictions = scores.max(1)\n",
    "            # we want the class with max probability\n",
    "            # hence we take max from the last dimension\n",
    "            # for each image in the batch\n",
    "            num_correct += (predictions == y).sum()\n",
    "            # prediction is of shape (batch) and when you compare both\n",
    "            # you get array of size(batch) with entries of either 1 or 0\n",
    "            # by summing them you get number of correct predictions\n",
    "\n",
    "            num_sample += predictions.size(0)\n",
    "\n",
    "        acc = (float(num_correct) / float(num_sample)*100)\n",
    "        print(f'Got {float(num_correct)/(float(num_sample))*100:.2f} accuracy')\n",
    "\n",
    "        # if this was used to check accuracy for every epoch during training\n",
    "        # add the code\n",
    "        # model.train()\n",
    "        # return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_accuracy(train_loader, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
