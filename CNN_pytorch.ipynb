{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = 28*28  # we receive the size of images in MNIST as 28x28\n",
    "# as we are having neural network the input shape\n",
    "# will be 28*28 and we will flatten each image to\n",
    "# match the input size of model\n",
    "classes = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 3\n",
    "model_file = 'model_run/CNN.pth.tar'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=in_channels, out_channels=4,\n",
    "                              kernel_size=(3, 3), stride=(1, 1),\n",
    "                              padding=(1, 1))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        self.cnn2 = nn.Conv2d(in_channels=4, out_channels=8,\n",
    "                              kernel_size=(3, 3), stride=(1, 1),\n",
    "                              padding=(1, 1))\n",
    "        self.fc1 = nn.Linear(8*14*14, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.cnn1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.cnn2(x))\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(1, 10)  # MNIST has black and white dataset so in_channels =1\n",
    "# and output of the model is 10 differnet classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint saving function\n",
    "def save_checkpoint(state, filename=model_file):\n",
    "    if (state['epoch'] == 0):\n",
    "        print(\"===> Saving Checkpoint \")\n",
    "        torch.save(state, filename)\n",
    "        return\n",
    "    else:\n",
    "        checkpoint = torch.load(filename)\n",
    "        if (checkpoint['accuracy'] < state['accuracy']):\n",
    "            print(\"===> Saving Checkpoint \")\n",
    "            torch.save(state, filename)\n",
    "        else:\n",
    "            return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy check function\n",
    "def check_accuracy(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print(\"testing on training data\")\n",
    "    else:\n",
    "        print(\"Testing on Testing data\")\n",
    "    num_correct = 0\n",
    "    num_sample = 0\n",
    "    model.eval()  # We're telling model to shift to eval mode\n",
    "\n",
    "    with torch.no_grad():   # we dont want the model to calculate the graidents\n",
    "        # just the outputs are required as model is already trained\n",
    "        for x, y in loader:\n",
    "            scores = model(x)\n",
    "            # scores.max = ([max_values], [indices of max value])\n",
    "            # Shape = batchsize\n",
    "            # here indices represent class with max prob\n",
    "            _, predictions = scores.max(1)\n",
    "            # we want the class with max probability\n",
    "            # hence we take max from the last dimension\n",
    "            # for each image in the batch\n",
    "            num_correct += (predictions == y).sum()\n",
    "            # prediction is of shape (batch) and when you compare both\n",
    "            # you get array of size(batch) with entries of either 1 or 0\n",
    "            # by summing them you get number of correct predictions\n",
    "\n",
    "            num_sample += predictions.size(0)\n",
    "\n",
    "        acc = round((float(num_correct) / float(num_sample)*100), ndigits=2)\n",
    "        # print(f'Got {float(num_correct)/(float(num_sample))*100:.2f} accuracy')\n",
    "\n",
    "        # if this was used to check accuracy for every epoch during training\n",
    "        # add the code\n",
    "        model.train()\n",
    "        return acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root=\"dataset/\", train=True,\n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "test_dataset = datasets.MNIST(root=\"dataset/\", train=False,\n",
    "                              transform=transforms.ToTensor(),\n",
    "                              download=True)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True,\n",
    "                          batch_size=batch_size, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (os.path.isfile(model_file)):\n",
    "    prev_model = torch.load(model_file)\n",
    "    model.load_state_dict(prev_model['state_dict'])\n",
    "    max_acc = prev_model['accuracy']\n",
    "else:\n",
    "    max_acc = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epochs in range(num_epochs):\n",
    "\n",
    "    for batch_idx, (train, targets) in enumerate(train_loader):\n",
    "        data = train\n",
    "        targets = targets  # now we have loaded the data\n",
    "        print(targets.shape)\n",
    "        print(data.shape)\n",
    "        # now fit the model\n",
    "        scores = model(data)\n",
    "        print(scores.shape)\n",
    "        loss = metrics(scores, targets)\n",
    "        # CAlculate gradient of the loss wrt the parameters\n",
    "        # set optimizer's gradients to zero for every batch initially\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent\n",
    "        optimizer.step()\n",
    "\n",
    "    acc = check_accuracy(train_loader, model)\n",
    "    print(f'For epoch : {epochs} accuracy is {acc}')\n",
    "\n",
    "    if (acc > max_acc):\n",
    "        max_acc = acc\n",
    "        checkpoint = {'state_dict': model.state_dict(),\n",
    "                      'optimizer': optimizer.state_dict(),\n",
    "                      'accuracy': acc,\n",
    "                      'epoch': epochs}\n",
    "        save_checkpoint(checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_accuracy(train_loader, model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
